{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a27fc93",
   "metadata": {},
   "source": [
    "# TerraClassify: Deep Learning-based Land Cover Classification and Semantic Segmentation for Sustainable Development and Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb51bea",
   "metadata": {},
   "source": [
    "### Contributors:\n",
    "\n",
    "#### Dharu Piraba Muguntharaman (dm5596@nyu.edu), Raunak Bhupal (rb4986@nyu.edu), Shamyukta Rajagopal (sr6626@nyu.edu)\n",
    "\n",
    "We have selected this topic to work on in accordance with the Final Project for CS-GY 6953 Deep Learning for the Academic Semester Spring 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c1f72",
   "metadata": {},
   "source": [
    "Implementation has been provided for the code to run on Colab\n",
    "\n",
    "We uploaded the data on Google Drive and then mount this drive on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/data/data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1b211",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6345087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from patchify import patchify\n",
    "\n",
    "minmaxscaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f4a30",
   "metadata": {},
   "source": [
    "Let's load the dataset first\n",
    "\n",
    "There are 683 satellite and it's corresponding mask images in the training_data folder, but due to compute restrictions we were unable to load the entire dataset and thus just took the first 300 satellite and it's corresponding mask images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e801d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Path to the directory containing images\n",
    "image_data_path = '/content/data/training_data/images/'\n",
    "mask_data_path = '/content/data/training_data/masks/'\n",
    "\n",
    "count = 0\n",
    "image_patch_size = 256\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "files = sorted(os.listdir(image_data_path))\n",
    "\n",
    "#Iterate over files in the directory\n",
    "for filename in files:\n",
    "    if count == 300:\n",
    "        break\n",
    "    count+=1\n",
    "    if filename.endswith('.jpg'):\n",
    "        file_path = os.path.join(image_data_path, filename)\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is not None:\n",
    "            #image shape is (height,width)\n",
    "            width = (image.shape[1]//image_patch_size)*image_patch_size\n",
    "            height = (image.shape[0]//image_patch_size)*image_patch_size\n",
    "            #convert to PIL\n",
    "            image = Image.fromarray(image)\n",
    "            #crop is (left, top, right, bottom)\n",
    "            image = image.crop((0,0, width, height))\n",
    "            image = np.array(image)\n",
    "            #create patches of images\n",
    "            patched_images = patchify(image,(image_patch_size, image_patch_size,3),step =image_patch_size)\n",
    "            for i in range(patched_images.shape[0]):\n",
    "                for j in range(patched_images.shape[1]): \n",
    "                    individual_image = patched_images[i,j,:,:]\n",
    "                    individual_image  = minmaxscaler.fit_transform(individual_image.reshape(-1, individual_image.shape[-1])).reshape(individual_image.shape)\n",
    "                    individual_image  = individual_image[0]\n",
    "            image_dataset.append(image)\n",
    "\n",
    "count = 0\n",
    "files = sorted(os.listdir(mask_data_path))\n",
    "#Iterate over files in the directory\n",
    "for filename in files:\n",
    "    if count == 300:\n",
    "        break\n",
    "    count+=1\n",
    "    if filename.endswith('.png'):\n",
    "        file_path = os.path.join(mask_data_path, filename)\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is not None:\n",
    "            #need to convert masks to RGB in accordance with the metadata\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            #image shape is (height,width)\n",
    "            width = (image.shape[1]//image_patch_size)*image_patch_size\n",
    "            height = (image.shape[0]//image_patch_size)*image_patch_size\n",
    "            #convert to PIL\n",
    "            image = Image.fromarray(image)\n",
    "            #crop is (left, top, right, bottom)\n",
    "            image = image.crop((0,0, width, height))\n",
    "            image = np.array(image)\n",
    "            #create patches of images\n",
    "            patched_images = patchify(image,(image_patch_size, image_patch_size,3),step =image_patch_size)\n",
    "            for i in range(patched_images.shape[0]):\n",
    "                for j in range(patched_images.shape[1]): \n",
    "                    individual_image = patched_images[i,j,:,:]\n",
    "                    individual_image  = individual_image[0]\n",
    "            mask_dataset.append(image)\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = np.array(image_dataset)\n",
    "mask_dataset = np.array(mask_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to plot a random image and it's mask\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "random_image_id = random.randint(0, len(image_dataset))  # viewing random images from the dataset \n",
    "print(random_image_id)\n",
    "\n",
    "#plotting the images \n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_dataset[random_image_id])\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_dataset[random_image_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad2e23",
   "metadata": {},
   "source": [
    "Creating the different classes. Values are assigned in accordance with the metadata description for this dataset, available on kaggle : https://www.kaggle.com/datasets/balraj98/deepglobe-land-cover-classification-dataset?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3935a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_urban_land = np.array([0,255,255])\n",
    "\n",
    "class_agriculture_land = np.array([255,255,0])\n",
    "\n",
    "class_rangeland = np.array([255,0,255])\n",
    "\n",
    "class_forest_land = np.array([0,255,0])\n",
    "\n",
    "class_water = np.array([0,0,255])\n",
    "\n",
    "class_barren_land = np.array([255,255,255])\n",
    "\n",
    "class_unknown = np.array([0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_label(label):\n",
    "    label_segment = np.zeros(label.shape, dtype=np.uint8)\n",
    "    label_segment[np.all(label == class_urban_land , axis=-1)] = 0\n",
    "    label_segment[np.all(label == class_agriculture_land, axis=-1)] = 1\n",
    "    label_segment[np.all(label == class_rangeland , axis=-1)] = 2\n",
    "    label_segment[np.all(label == class_forest_land, axis=-1)] = 3\n",
    "    label_segment[np.all(label == class_water, axis=-1)] = 4\n",
    "    label_segment[np.all(label == class_barren_land, axis=-1)] = 5\n",
    "    label_segment[np.all(label == class_unknown, axis=-1)] = 6\n",
    "    label_segment = label_segment[:,:,0]\n",
    "    return label_segment\n",
    "\n",
    "#Creating labels\n",
    "labels = []\n",
    "for i in range(len(mask_dataset)):\n",
    "    label = rgb_to_label(mask_dataset[i])\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "labels = np.expand_dims(labels, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b217e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(labels)\n",
    "classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbe399",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total unique labels based on masks: \",format(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the labels to categorical dataset\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "labels_categorical_dataset = to_categorical(labels, num_classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, labels_categorical_dataset, test_size =0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q segmentation-models\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss coefficient\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    y_true_flatten = K.flatten(y_true)\n",
    "    y_pred_flatten = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
    "    final_coef_value = (intersection + 1.0) / (K.sum(y_true_flatten) + K.sum(y_pred_flatten) - intersection + 1.0)\n",
    "    return final_coef_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596e53e6",
   "metadata": {},
   "source": [
    "Let's define the Unet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e38c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(n_classes=classes, image_height=256, image_width=256, image_channels=1):\n",
    "\n",
    "    inputs = Input((image_height, image_width, image_channels))\n",
    "    \n",
    "    c1 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(inputs)\n",
    "    c1 = Dropout(0.2)(c1)\n",
    "    c1 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "\n",
    "    c2 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n",
    "    c2 = Dropout(0.2)(c2)\n",
    "    c2 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "\n",
    "    c3 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "\n",
    "    c4 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "\n",
    "    c5 = Conv2D(512, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n",
    "    c5 = Dropout(0.2)(c5)\n",
    "    c5 = Conv2D(512, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n",
    "\n",
    "\n",
    "    u6 = Conv2DTranspose(256, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n",
    "    c8 = Dropout(0.2)(c8)\n",
    "    c8 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n",
    "    c9 = Dropout(0.2)(c9)\n",
    "    c9 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n",
    "\n",
    "    outputs = Conv2D(n_classes, (1,1), activation=\"softmax\")(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a1d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\", jaccard_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = X_train.shape[1]\n",
    "image_width = X_train.shape[2]\n",
    "image_channels = X_train.shape[3]\n",
    "\n",
    "model = unet_model(n_classes=classes, image_height=image_height, image_width=image_width, image_channels=image_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e034a",
   "metadata": {},
   "source": [
    "Below we are defining the weights, by equally dividing the values among the 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24972def",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.1428, 0.1428, 0.1428, 0.1428, 0.1428, 0.1428, 0.1428]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfce033",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = sm.losses.DiceLoss(class_weights = weights)\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(0.0001)\n",
    "model.compile(optimizer=optimizer, loss=total_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce90cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(X_train, y_train,batch_size=16,verbose=1,epochs=100,validation_data=(X_test, y_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5955fb5",
   "metadata": {},
   "source": [
    "Let's visualize the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d797d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (18, 5))\n",
    "\n",
    "loss = model_history.history['loss']            \n",
    "val_loss = model_history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "axs[0].plot(epochs, loss, 'y', label=\"Training Loss\")\n",
    "axs[0].plot(epochs, val_loss, 'r', label=\"Validation Loss\")\n",
    "axs[0].set_title(\"My_Unet_Training Vs Validation Loss\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "jaccard_coef = model_history.history['jaccard_coef']       \n",
    "val_jaccard_coef = model_history.history['val_jaccard_coef']\n",
    "epochs = range(1, len(jaccard_coef) + 1)\n",
    "\n",
    "axs[1].plot(epochs, jaccard_coef, 'y', label=\"Training IoU\")\n",
    "axs[1].plot(epochs, val_jaccard_coef, 'r', label=\"Validation IoU\")\n",
    "axs[1].set_title(\"My_Unet_Training Vs Validation IoU\")\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.save('loss_iou.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize = (18, 5))\n",
    "\n",
    "accuracy = model_history.history['accuracy']             \n",
    "val_accuracy = model_history.history['val_accuracy']     \n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "axs[0].plot(epochs, accuracy, 'y', label=\"Training accuracy\")\n",
    "axs[0].plot(epochs, val_accuracy, 'r', label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"My_Unet_Training Vs Validation accuracy\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"accuracy\")\n",
    "axs[0].legend()\n",
    "plt.save('accuracy_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d33c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=3)\n",
    "y_test_argmax = np.argmax(y_test, axis=3)\n",
    "\n",
    "test_image_number = random.randint(0, len(X_test))\n",
    "\n",
    "test_image = X_test[test_image_number]\n",
    "ground_truth_image = y_test_argmax[test_image_number]\n",
    "\n",
    "test_image_input = np.expand_dims(test_image, 0)\n",
    "\n",
    "prediction = model.predict(test_image_input)\n",
    "predicted_image = np.argmax(prediction, axis=3)\n",
    "predicted_image = predicted_image[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdeba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.subplot(231)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(test_image)\n",
    "plt.subplot(232)\n",
    "plt.title(\"Original Masked image\")\n",
    "plt.imshow(ground_truth_image)\n",
    "plt.subplot(233)\n",
    "plt.title(\"Predicted Image\")\n",
    "plt.imshow(predicted_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa4430c",
   "metadata": {},
   "source": [
    "So the above result is what we get after training our dataset on the Unet model\n",
    "\n",
    "Now we will explore other models to see if we are able to get better accuracies and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5aff3c",
   "metadata": {},
   "source": [
    "### Unet with ResNet34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0e1ed",
   "metadata": {},
   "source": [
    "Here we will train our dataset on the Unet model with Resnet34 as it's backbone to see if there are any better results or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=classes)\n",
    "model.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=metrics)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_resnet34_Unet = model.fit(x=X_train,y=y_train,batch_size=16,epochs=100,verbose=1,validation_data=(X_test, y_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de36995",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (18, 5))\n",
    "\n",
    "loss = loss =  history_resnet34_Unet.history['loss']             \n",
    "val_loss =  history_resnet34_Unet.history['val_loss']     \n",
    "epochs = range(1, len(loss) + 1)\n",
    "axs[0].plot(epochs, loss, 'y', label=\"Training Loss\")\n",
    "axs[0].plot(epochs, val_loss, 'r', label=\"Validation Loss\")\n",
    "axs[0].set_title(f\"Resnet_Training Vs Validation Loss for\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "jaccard_coef =  history_resnet34_Unet.history['jaccard_coef']               \n",
    "val_jaccard_coef =  history_resnet34_Unet.history['val_jaccard_coef']       \n",
    "epochs = range(1, len(jaccard_coef) + 1)\n",
    "\n",
    "axs[1].plot(epochs, jaccard_coef, 'y', label=\"Training IoU\")\n",
    "axs[1].plot(epochs, val_jaccard_coef, 'r', label=\"Validation IoU\")\n",
    "axs[1].set_title(f\"Resnet_Training Vs Validation IoU\")\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf04efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize = (18, 5))\n",
    "\n",
    "accuracy =history_resnet34_Unet.history['accuracy']             \n",
    "val_accuracy = history_resnet34_Unet.history['val_accuracy']     \n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "axs[0].plot(epochs, accuracy, 'y', label=\"Training accuracy\")\n",
    "axs[0].plot(epochs, val_accuracy, 'r', label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"Resnet_Training Vs Validation accuracy\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"accuracy\")\n",
    "axs[0].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea9e60",
   "metadata": {},
   "source": [
    "### Unet with VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cb891",
   "metadata": {},
   "source": [
    "Here we will train our dataset on the Unet model with VGG19 as it's backbone to see if there are any better results or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1172c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'vgg19'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=total_classes)\n",
    "model.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=metrics)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg19_Unet  = model.fit(x=X_train,y=y_train,batch_size=16 ,epochs=100,verbose=1,validation_data=(X_test, y_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (18, 5))\n",
    "\n",
    "loss = history_vgg19_Unet.history['loss']             \n",
    "val_loss = history_vgg19_Unet.history['val_loss']     \n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "axs[0].plot(epochs, loss, 'y', label=\"Training Loss\")\n",
    "axs[0].plot(epochs, val_loss, 'r', label=\"Validation Loss\")\n",
    "axs[0].set_title(\"Vgg19_Training Vs Validation Loss\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "jaccard_coef = history_vgg19_Unet.history['jaccard_coef']               \n",
    "val_jaccard_coef = history_vgg19_Unet.history['val_jaccard_coef']       \n",
    "epochs = range(1, len(jaccard_coef) + 1)\n",
    "\n",
    "axs[1].plot(epochs, jaccard_coef, 'y', label=\"Training IoU\")\n",
    "axs[1].plot(epochs, val_jaccard_coef, 'r', label=\"Validation IoU\")\n",
    "axs[1].set_title(\"Vgg19_Training Vs Validation IoU\")\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57976cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize = (18, 5))\n",
    "\n",
    "accuracy =history_vgg19_Unet.history['accuracy']             \n",
    "val_accuracy = history_vgg19_Unet.history['val_accuracy']     \n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "axs[0].plot(epochs, accuracy, 'y', label=\"Training accuracy\")\n",
    "axs[0].plot(epochs, val_accuracy, 'r', label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"VGG19_Training Vs Validation accuracy\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"accuracy\")\n",
    "axs[0].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb60d45",
   "metadata": {},
   "source": [
    "### Unet with InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816eb6b4",
   "metadata": {},
   "source": [
    "Here we will train our dataset on the Unet model with InceptionV3 as it's backbone to see if there are any better results or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d83afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'inceptionv3'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=total_classes)\n",
    "model.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=metrics)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58444ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_inceptionv3_Unet  = model.fit(x=X_train,y=y_train,batch_size=16,epochs=100,verbose=1,validation_data=(X_test, y_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b30d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (18, 5))\n",
    "\n",
    "loss = history_inceptionv3_Unet.history['loss']            \n",
    "val_loss = history_inceptionv3_Unet.history['val_loss']    \n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "axs[0].plot(epochs, loss, 'y', label=\"Training Loss\")\n",
    "axs[0].plot(epochs, val_loss, 'r', label=\"Validation Loss\")\n",
    "axs[0].set_title(\"InceptionV3_Training Vs Validation Loss\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "jaccard_coef = history_inceptionv3_Unet.history['jaccard_coef']               \n",
    "val_jaccard_coef = history_inceptionv3_Unet.history['val_jaccard_coef']       \n",
    "epochs = range(1, len(jaccard_coef) + 1)\n",
    "\n",
    "axs[1].plot(epochs, jaccard_coef, 'y', label=\"Training IoU\")\n",
    "axs[1].plot(epochs, val_jaccard_coef, 'r', label=\"Validation IoU\")\n",
    "axs[1].set_title(\"InceptionV3_Training Vs Validation IoU\")\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb327166",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (18, 5))\n",
    "\n",
    "accuracy =history_inceptionv3_Unet.history['accuracy']             \n",
    "val_accuracy = history_inceptionv3_Unet.history['val_accuracy']     \n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "axs[0].plot(epochs, accuracy, 'y', label=\"Training accuracy\")\n",
    "axs[0].plot(epochs, val_accuracy, 'r', label=\"Validation accuracy\")\n",
    "axs[0].set_title(\"InceptionV3_Training Vs Validation accuracy\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"accuracy\")\n",
    "axs[0].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
